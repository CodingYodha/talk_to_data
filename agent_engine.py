import json
from router import determine_complexity
from database_utils import db_manager
from prompts import build_system_prompt
from llm_client import call_llm

def process_question(user_question):
    """
    Orchestrates the Text-to-SQL logic with execution and self-correction:
    1. Determine complexity (Router).
    2. Get schema context (DB).
    3. Build System Prompt (Props).
    4. Call LLM to get initial SQL.
    5. Execute SQL.
    6. If error, retry once with 'pro' model.
    7. Return comprehensive result.
    
    Args:
        user_question (str): The user's natural language question.
        
    Returns:
        dict: Contains question, steps (thought/sql/error), final_data, status.
    """
    response_structure = {
        "question": user_question,
        "model_used": None,
        "steps": [],
        "final_data": None,
        "status": "pending"
    }

    # 1. Router
    complexity = determine_complexity(user_question)
    response_structure["model_used"] = complexity
    
    # 2. Database Context
    db = db_manager()
    schema_summary = db.get_schema_summary()
    
    # 3. Prompt Construction
    system_prompt = build_system_prompt(schema_summary)
    full_prompt = f"{system_prompt}\n\nUser Question: {user_question}"
    
    # 4. LLM Call (Attempt 1)
    step_info = {"attempt": 1, "thought": None, "sql": None, "error": None}
    
    try:
        raw_response = call_llm(full_prompt, model_type=complexity)
        parsed_response = json.loads(raw_response)
        
        step_info["thought"] = parsed_response.get("thought_process")
        step_info["sql"] = parsed_response.get("sql_query")
        
        # 5. Execution
        if step_info["sql"]:
            df, error = db.execute_query(step_info["sql"])
            
            if error:
                step_info["error"] = error
                response_structure["steps"].append(step_info)
                
                # --- RETRY LOOP (Max 1) ---
                print(f"Attempt 1 failed: {error}. Retrying...")
                
                retry_prompt = f"""
                The previous query failed with error: {error}
                The query was: {step_info['sql']}
                
                Please correct the SQL query to answer the original question: "{user_question}"
                
                Ensure you return the response in the same STRICT JSON format:
                {{
                   "thought_process": "Reasoning for the fix...",
                   "sql_query": "Corrected SQL..."
                }}
                """
                
                # Force 'pro' model for stronger reasoning on retry
                raw_response_retry = call_llm(retry_prompt, model_type='pro')
                parsed_response_retry = json.loads(raw_response_retry)
                
                retry_step_info = {
                    "attempt": 2,
                    "thought": parsed_response_retry.get("thought_process"),
                    "sql": parsed_response_retry.get("sql_query"),
                    "error": None
                }
                
                if retry_step_info["sql"]:
                    df_retry, error_retry = db.execute_query(retry_step_info["sql"])
                    if error_retry:
                        retry_step_info["error"] = error_retry
                        response_structure["status"] = "error"
                    else:
                        response_structure["final_data"] = df_retry.to_dict(orient='records')
                        response_structure["status"] = "success"
                
                response_structure["steps"].append(retry_step_info)
                
            else:
                # Success on Attempt 1
                response_structure["final_data"] = df.to_dict(orient='records')
                response_structure["status"] = "success"
                response_structure["steps"].append(step_info)
        else:
            step_info["error"] = "No SQL generated by LLM"
            response_structure["status"] = "error"
            response_structure["steps"].append(step_info)

    except json.JSONDecodeError:
        step_info["error"] = "Failed to parse LLM response as JSON"
        response_structure["status"] = "error"
        response_structure["steps"].append(step_info)
    except Exception as e:
        step_info["error"] = f"An unexpected error occurred: {str(e)}"
        response_structure["status"] = "error"
        response_structure["steps"].append(step_info)
        
    return response_structure
